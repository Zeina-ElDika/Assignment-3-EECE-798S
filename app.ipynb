{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8445e8e3",
   "metadata": {},
   "source": [
    "# GiftMuse Atelier Concierge - Gemini Colab App\n",
    "\n",
    "Everything required to demo the GiftMuse Atelier gifting concierge in Google Colab lives in this notebook. It bundles a Gemini-powered agent, lead & feedback logging, sample interactions, and a colorful Gradio chat UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4a68a6",
   "metadata": {},
   "source": [
    "## Quick Start\n",
    "1. Place your `.env` file alongside this notebook (already populated per your request).\n",
    "2. Open the notebook in Colab.\n",
    "3. (Optional) Run the install cell if the required packages are missing.\n",
    "4. Execute the remaining cells sequentially to chat with the concierge and view logged leads/feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61ae5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: install dependencies if your environment does not already have them.\n",
    "# Uncomment if needed.\n",
    "# !pip install -q google-generativeai gradio PyPDF2 python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ced6c93",
   "metadata": {},
   "source": [
    "## Load Gemini API Key from `.env`\n",
    "Your key is loaded securely via `python-dotenv` so it is not hard-coded in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee99920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError('GEMINI_API_KEY is missing. Add it to your .env file before proceeding.')\n",
    "GEMINI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d31d0d3",
   "metadata": {},
   "source": [
    "## Preferred Gemini Models\n",
    "The agent will default to `models/gemini-2.5-flash` and automatically fall back to additional options if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44b72a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CANDIDATES = [\n",
    "    'models/gemini-2.5-flash',\n",
    "    'models/gemini-1.5-flash-latest',\n",
    "    'models/gemini-1.5-flash',\n",
    "    'models/gemini-1.5-flash-8b-latest',\n",
    "    'models/gemini-1.5-pro-latest',\n",
    "    'models/gemini-1.5-pro',\n",
    "]\n",
    "MODEL_CANDIDATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9238260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import GenerationConfig\n",
    "from google.api_core import exceptions as google_exceptions\n",
    "\n",
    "# --- Business content -------------------------------------------------------\n",
    "summary_text = \"GiftMuse Atelier is a gifting intelligence studio that blends warm human curation with agile AI research. We deliver quick, heartfelt gift ideas that feel tailor-made for every person and milestone.\\n\\nWe focus on concierge gifting paths: on-demand scouting sprints, event gifting programs, and the GiftGlow Corporate service for sales and HR teams. Clients trust our 120 artisan maker partners and sustainability pledge donating one percent of concierge packages to creativity grants.\"\n",
    "profile_snippet = \"GiftMuse Atelier Business Snapshot\\nMission: Replace gifting stress with confidence through curated, sentimental suggestions.\\nServices: Gift scouting sprints, signature event gifting programs, GiftGlow Corporate concierge.\\nTeam: Ava Moreno (Founder), Idris Patel (CTO), Priya Das (Customer Journey Lead).\\nProcess: Blend human curiosity with AI taste modeling to spotlight artisan and sustainable vendors.\\nValue: Collective of 120 makers, sustainability pledge, wrap-and-delivery partners.\\nTone: Warm, organized, proactive about transforming occasions into memories.\"\n",
    "\n",
    "# --- Data directory for logs ------------------------------------------------\n",
    "DATA_DIR = Path(\"giftmuse_data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "LEADS_LOG = DATA_DIR / \"leads.jsonl\"\n",
    "FEEDBACK_LOG = DATA_DIR / \"feedback.jsonl\"\n",
    "\n",
    "# --- Tool helpers -----------------------------------------------------------\n",
    "def _timestamp() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat()\n",
    "\n",
    "\n",
    "def _write_log(path: Path, payload: Dict[str, str]) -> None:\n",
    "    with path.open(\"a\", encoding=\"utf-8\") as handle:\n",
    "        handle.write(json.dumps(payload, ensure_ascii=False))\n",
    "        handle.write(\"\\n\")\n",
    "\n",
    "\n",
    "def record_customer_interest(email: str = \"\", name: str = \"\", message: Optional[str] = None) -> str:\n",
    "    entry = {\n",
    "        \"type\": \"lead\",\n",
    "        \"timestamp\": _timestamp(),\n",
    "        \"name\": (name or \"\").strip(),\n",
    "        \"email\": (email or \"\").strip().lower(),\n",
    "        \"message\": (message or \"\").strip(),\n",
    "    }\n",
    "    _write_log(LEADS_LOG, entry)\n",
    "    if entry[\"name\"] or entry[\"email\"]:\n",
    "        return \"Thanks! I captured your details so our concierge can reach out soon.\"\n",
    "    return \"Appreciate the interest. I logged the note for our concierge team.\"\n",
    "\n",
    "\n",
    "def record_feedback(question: str) -> str:\n",
    "    entry = {\n",
    "        \"type\": \"feedback\",\n",
    "        \"timestamp\": _timestamp(),\n",
    "        \"question\": (question or \"\").strip(),\n",
    "    }\n",
    "    _write_log(FEEDBACK_LOG, entry)\n",
    "    return \"I saved that question for the GiftMuse Atelier team so we can follow up promptly.\"\n",
    "\n",
    "\n",
    "GEMINI_FUNCTION_DECLARATIONS = [\n",
    "    {\n",
    "        \"name\": \"record_customer_interest\",\n",
    "        \"description\": \"Capture a lead's contact details and notes for concierge follow-up.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"email\": {\"type\": \"string\", \"description\": \"Customer email address, if supplied.\"},\n",
    "                \"name\": {\"type\": \"string\", \"description\": \"Customer name or representative.\"},\n",
    "                \"message\": {\"type\": \"string\", \"description\": \"Any context about their gifting needs or requests.\"},\n",
    "            },\n",
    "            \"required\": [],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"record_feedback\",\n",
    "        \"description\": \"Log unanswered questions or feedback for the GiftMuse Atelier team.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"question\": {\"type\": \"string\", \"description\": \"The feedback item or question we could not answer.\"},\n",
    "            },\n",
    "            \"required\": [\"question\"],\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "# --- Agent utilities -------------------------------------------------------\n",
    "def build_system_prompt(summary: str, profile: str) -> str:\n",
    "    return (\n",
    "        \"You are the concierge for GiftMuse Atelier, a joyful gifting intelligence studio. \"\n",
    "        \"Reply with upbeat, organized guidance grounded in the business profile. \"\n",
    "        \"Suggest creative gift paths quickly, highlight artisan or sustainable makers, and invite clients to share contact details. \"\n",
    "        \"If you lack information, apologize briefly and call the feedback tool so the team can follow up.\\n\\n\"\n",
    "        f\"Business summary:\\n{summary}\\n\\nSnapshot from the detailed profile:\\n{profile}\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "class GiftMuseAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        api_key: str,\n",
    "        model_candidates: Optional[List[str]] = None,\n",
    "        system_prompt: Optional[str] = None,\n",
    "    ) -> None:\n",
    "        if not api_key:\n",
    "            raise ValueError(\"Gemini API key is required.\")\n",
    "        genai.configure(api_key=api_key)\n",
    "\n",
    "        defaults = [\n",
    "            \"models/gemini-2.5-flash\",\n",
    "            \"models/gemini-1.5-flash-latest\",\n",
    "            \"models/gemini-1.5-flash\",\n",
    "            \"models/gemini-1.5-flash-8b-latest\",\n",
    "            \"models/gemini-1.5-pro-latest\",\n",
    "            \"models/gemini-1.5-pro\",\n",
    "        ]\n",
    "        supplied = model_candidates or []\n",
    "        self.model_candidates: List[str] = []\n",
    "        for candidate in supplied + defaults:\n",
    "            if candidate and candidate not in self.model_candidates:\n",
    "                self.model_candidates.append(candidate)\n",
    "\n",
    "        self.system_prompt = system_prompt or build_system_prompt(summary_text, profile_snippet)\n",
    "        self._model = None\n",
    "        self._chat = None\n",
    "        self._active_index = 0\n",
    "        self._init_chat(start_index=0)\n",
    "\n",
    "    def _init_chat(self, start_index: int) -> None:\n",
    "        last_error: Optional[Exception] = None\n",
    "        for idx in range(start_index, len(self.model_candidates)):\n",
    "            candidate = self.model_candidates[idx]\n",
    "            try:\n",
    "                model = genai.GenerativeModel(\n",
    "                    model_name=candidate,\n",
    "                    system_instruction=self.system_prompt,\n",
    "                    tools=[{\"function_declarations\": GEMINI_FUNCTION_DECLARATIONS}],\n",
    "                )\n",
    "                chat = model.start_chat(history=[])\n",
    "                self._model = model\n",
    "                self._chat = chat\n",
    "                self._active_index = idx\n",
    "                self.model_name = candidate\n",
    "                if idx != start_index:\n",
    "                    print(f\"Switched to Gemini model: {candidate}\")\n",
    "                else:\n",
    "                    print(f\"Using Gemini model: {candidate}\")\n",
    "                return\n",
    "            except (\n",
    "                google_exceptions.NotFound,\n",
    "                google_exceptions.FailedPrecondition,\n",
    "                google_exceptions.PermissionDenied,\n",
    "            ) as exc:\n",
    "                last_error = exc\n",
    "                continue\n",
    "\n",
    "        raise RuntimeError(\n",
    "            \"Unable to initialize a Gemini model. \"\n",
    "            f\"Tried: {', '.join(self.model_candidates)}. Last error: {last_error}\"\n",
    "        )\n",
    "\n",
    "    def _rotate_model(self) -> None:\n",
    "        next_index = self._active_index + 1\n",
    "        if next_index >= len(self.model_candidates):\n",
    "            raise RuntimeError(\n",
    "                \"All configured Gemini models returned errors. \"\n",
    "                f\"Models tried: {', '.join(self.model_candidates)}\"\n",
    "            )\n",
    "        self._init_chat(start_index=next_index)\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_text(response) -> str:\n",
    "        for candidate in response.candidates:\n",
    "            parts = []\n",
    "            for part in candidate.content.parts:\n",
    "                text = getattr(part, \"text\", None)\n",
    "                if text:\n",
    "                    parts.append(text)\n",
    "            if parts:\n",
    "                return \"\\n\".join(parts).strip()\n",
    "        return \"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _next_tool_call(response) -> Optional[Dict[str, object]]:\n",
    "        for candidate in response.candidates:\n",
    "            for part in candidate.content.parts:\n",
    "                call = getattr(part, \"function_call\", None)\n",
    "                if call:\n",
    "                    return {\"name\": call.name, \"args\": dict(call.args or {})}\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def _invoke_tool(name: str, arguments: Dict[str, object]) -> Dict[str, object]:\n",
    "        if name == \"record_customer_interest\":\n",
    "            result_text = record_customer_interest(\n",
    "                email=arguments.get(\"email\", \"\"),\n",
    "                name=arguments.get(\"name\", \"\"),\n",
    "                message=arguments.get(\"message\"),\n",
    "            )\n",
    "        elif name == \"record_feedback\":\n",
    "            result_text = record_feedback(question=arguments.get(\"question\", \"\"))\n",
    "        else:\n",
    "            result_text = \"Tool not implemented.\"\n",
    "        return {\n",
    "            \"function_response\": {\n",
    "                \"name\": name,\n",
    "                \"response\": {\"text\": result_text},\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def respond(self, user_input: str, temperature: float = 0.6) -> str:\n",
    "        attempts = 0\n",
    "        while attempts < len(self.model_candidates):\n",
    "            try:\n",
    "                config = GenerationConfig(temperature=temperature)\n",
    "                response = self._chat.send_message(user_input, generation_config=config)\n",
    "                tool_call = self._next_tool_call(response)\n",
    "                while tool_call:\n",
    "                    tool_output = self._invoke_tool(tool_call[\"name\"], tool_call[\"args\"])\n",
    "                    response = self._chat.send_message(tool_output, generation_config=config)\n",
    "                    tool_call = self._next_tool_call(response)\n",
    "                return self._extract_text(response)\n",
    "            except (\n",
    "                google_exceptions.NotFound,\n",
    "                google_exceptions.FailedPrecondition,\n",
    "                google_exceptions.PermissionDenied,\n",
    "            ) as exc:\n",
    "                attempts += 1\n",
    "                if attempts >= len(self.model_candidates):\n",
    "                    raise RuntimeError(\n",
    "                        \"All configured Gemini models returned errors during respond(). \"\n",
    "                        f\"Models tried: {', '.join(self.model_candidates)}\"\n",
    "                    ) from exc\n",
    "                print(f\"{exc.__class__.__name__}: {exc} -- trying next model...\")\n",
    "                self._rotate_model()\n",
    "\n",
    "        raise RuntimeError(\"Unable to obtain a response from any Gemini model.\")\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self._chat = self._model.start_chat(history=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ef9f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = build_system_prompt(summary_text, profile_snippet)\n",
    "print(f\"System prompt characters: {len(SYSTEM_PROMPT)}\")\n",
    "agent = GiftMuseAgent(api_key=GEMINI_API_KEY, model_candidates=MODEL_CANDIDATES, system_prompt=SYSTEM_PROMPT)\n",
    "print(\"Active Gemini model:\", agent.model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5befa1c1",
   "metadata": {},
   "source": [
    "## Try the Concierge\n",
    "Uncomment the cells below to sample the assistant and trigger tool logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51d37a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.reset()\n",
    "# reply = agent.respond(\"We are hosting a sunset engagement; can you suggest a dazzling keepsake?\")\n",
    "# print(reply)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4fe94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reply = agent.respond(\"Capture my info: Layla Haddad, layla@example.com, 25 eco gift boxes for our partners.\")\n",
    "# print(reply)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4c62c2",
   "metadata": {},
   "source": [
    "## Launch Gradio Chat Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d0534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gift_theme = gr.themes.Soft(\n",
    "    primary_hue=\"pink\",\n",
    "    secondary_hue=\"rose\",\n",
    "    neutral_hue=\"gray\",\n",
    "    font=(\"Poppins\", \"sans-serif\"),\n",
    ")\n",
    "\n",
    "GIFT_CSS = \"\"\"\n",
    ".gradio-container {background: linear-gradient(135deg, #fff5f7 0%, #ffeefc 100%);}\n",
    ".chatbot .message.user {background: rgba(255, 182, 193, 0.25); border-radius: 18px;}\n",
    ".chatbot .message.bot {background: rgba(255, 255, 255, 0.95); border-radius: 18px; border: 1px solid #ffd4e5;}\n",
    ".gradio-container .title {font-weight: 700; letter-spacing: 0.02em;}\n",
    ".gradio-container button {background: #ff5c8a !important; border-color: #ff5c8a !important;}\n",
    "\"\"\"\n",
    "\n",
    "def gradio_respond(message, history):\n",
    "    if not history:\n",
    "        agent.reset()\n",
    "    return agent.respond(message)\n",
    "\n",
    "chat = gr.ChatInterface(\n",
    "    fn=gradio_respond,\n",
    "    type=\"messages\",\n",
    "    title=\"GiftMuse Atelier Concierge\",\n",
    "    description=\"Share the occasion, vibe, and budget - I will suggest handcrafted gifting paths and tee up our concierge team.\",\n",
    "    theme=gift_theme,\n",
    "    css=GIFT_CSS,\n",
    "    examples=[\n",
    "        \"I need a wow-worthy gift for a 10-year work anniversary celebration.\",\n",
    "        \"We are planning 30 sustainable welcome kits - can you recommend artisan makers?\",\n",
    "        \"Do you offer last-minute curation and gift wrapping for Dubai deliveries?\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "chat.launch(share=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcaebc8",
   "metadata": {},
   "source": [
    "## Review Logged Leads and Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3266541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for log_path in [LEADS_LOG, FEEDBACK_LOG]:\n",
    "    print(f\"\\n{log_path.name}:\")\n",
    "    if log_path.exists() and log_path.read_text().strip():\n",
    "        for line in log_path.read_text(encoding=\"utf-8\").splitlines():\n",
    "            print(json.loads(line))\n",
    "    else:\n",
    "        print(\"No entries yet.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}